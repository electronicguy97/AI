{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오디오 전처리를 위한 라이브러리\n",
    "import librosa\n",
    "import librosa.display as dsp\n",
    "from IPython.display import Audio\n",
    "\n",
    "#데이터 전처리를 위한 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT_DIR = 'c:/data/AudioMnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 재현성을 위하여 random seed 고정\n",
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:/data/AudioMnist/23/0_23_44.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:/data/AudioMnist/60/0_60_14.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:/data/AudioMnist/50/4_50_29.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:/data/AudioMnist/03/9_03_17.wav</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:/data/AudioMnist/04/0_04_31.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  label\n",
       "0  c:/data/AudioMnist/23/0_23_44.wav      0\n",
       "1  c:/data/AudioMnist/60/0_60_14.wav      0\n",
       "2  c:/data/AudioMnist/50/4_50_29.wav      4\n",
       "3  c:/data/AudioMnist/03/9_03_17.wav      9\n",
       "4  c:/data/AudioMnist/04/0_04_31.wav      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(ROOT_DIR+'train_audioMNIST.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22500 entries, 0 to 22499\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  22500 non-null  object\n",
      " 1   label      22500 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/data/AudioMnist/23/0_23_44.wav'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.file_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate: 16000 , audio shape: (10228,)\n",
      "length: 0.63925 secs\n"
     ]
    }
   ],
   "source": [
    "#소리는 기본적으로 특정 주파수를 가지는 sin함수들의 합\n",
    "#특정 시간에 주파수 성분이 어떻게 구성되어 있는지 확인\n",
    "#분석은 주파수 분석 기법을 많이 사용\n",
    "#음성 데이터 학습을 위해 아날로그 데이터로 되어있는 음성 데이터를 디지털 신호로 변환\n",
    "\n",
    "#sampling rate의 defult값은 22050Hz인데, 16000Hz으로 설정한 이유는 사람의 목소리는 대부분 16000Hz 안에 포함된다고 함.\n",
    "data, sample_rate = librosa.load(train.file_name[0], sr=16000)\n",
    "print('sample_rate:', sample_rate, ', audio shape:',data.shape)\n",
    "print('length:',data.shape[0]/float(sample_rate), 'secs')\n",
    "\n",
    "#초당 16000개(16000Hz 주파수)의 샘플을 가지고 있는 데이터라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:/data/AudioMnist/10/1_10_13.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:/data/AudioMnist/50/4_50_40.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:/data/AudioMnist/29/7_29_30.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:/data/AudioMnist/21/7_21_25.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:/data/AudioMnist/04/2_04_9.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name  label\n",
       "0  c:/data/AudioMnist/10/1_10_13.wav      1\n",
       "1  c:/data/AudioMnist/50/4_50_40.wav      4\n",
       "2  c:/data/AudioMnist/29/7_29_30.wav      7\n",
       "3  c:/data/AudioMnist/21/7_21_25.wav      7\n",
       "4   c:/data/AudioMnist/04/2_04_9.wav      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(ROOT_DIR+'test_audioMNIST.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        c:/data/AudioMnist/23/0_23_44.wav\n",
       "1        c:/data/AudioMnist/60/0_60_14.wav\n",
       "2        c:/data/AudioMnist/50/4_50_29.wav\n",
       "3        c:/data/AudioMnist/03/9_03_17.wav\n",
       "4        c:/data/AudioMnist/04/0_04_31.wav\n",
       "                       ...                \n",
       "22495    c:/data/AudioMnist/25/9_25_27.wav\n",
       "22496     c:/data/AudioMnist/28/7_28_4.wav\n",
       "22497     c:/data/AudioMnist/51/6_51_3.wav\n",
       "22498    c:/data/AudioMnist/03/0_03_26.wav\n",
       "22499     c:/data/AudioMnist/25/1_25_1.wav\n",
       "Name: file_name, Length: 22500, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset():\n",
    "    dataset = []\n",
    "    for file in tqdm(train['file_name'], colour='green'):\n",
    "        if 'wav' in file:\n",
    "            data, sr = librosa.load(file, sr=16000)\n",
    "            class_label = int(train[train.file_name == file].label)\n",
    "            dataset.append([data, class_label])\n",
    "\n",
    "    print('학습 데이터 생성 완료')\n",
    "    return pd.DataFrame(dataset, columns=['data', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset():\n",
    "    dataset = []\n",
    "    for file in tqdm(test['file_name'], colour='blue'):\n",
    "        if 'wav' in file:\n",
    "            data, sr = librosa.load(file, sr=16000)\n",
    "            class_label = int(test[test.file_name == file].label)\n",
    "            dataset.append([data, class_label])\n",
    "\n",
    "    print('검증 데이터 생성 완료')\n",
    "    return pd.DataFrame(dataset, columns=['data', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 22500/22500 [33:36<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 생성 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_wav = train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 7500/7500 [11:16<00:00, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 생성 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_wav = test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-2.5602067e-05, 5.113522e-06, -2.7813609e-05,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-5.5731027e-05, -0.00016563521, -0.0001917473...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-9.397177e-05, -0.00014913721, -0.0001808885,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.7803764e-05, 4.432852e-05, 3.4187742e-05, 5...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.00015264732, -0.000223465, -0.00018511842,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  label\n",
       "0  [-2.5602067e-05, 5.113522e-06, -2.7813609e-05,...      0\n",
       "1  [-5.5731027e-05, -0.00016563521, -0.0001917473...      0\n",
       "2  [-9.397177e-05, -0.00014913721, -0.0001808885,...      4\n",
       "3  [1.7803764e-05, 4.432852e-05, 3.4187742e-05, 5...      9\n",
       "4  [-0.00015264732, -0.000223465, -0.00018511842,...      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_wav.data)\n",
    "test_X = np.array(test_wav.data)\n",
    "\n",
    "train_y = np.array(train_wav.label)\n",
    "test_y = np.array(test_wav.label)\n",
    "\n",
    "#음성은 각각 다른 길이를 갖고 있음.\n",
    "# 길이가 가장 작은 길이의 데이터를 기준으로 데이터를 잘라서 사용 -> Under Sampling\n",
    "\n",
    "#가장 작은 길이 구하기\n",
    "def get_mini(data):\n",
    "    mini = 9999999\n",
    "    for i in data:\n",
    "        if len(i) < mini:\n",
    "            mini = len(i)\n",
    "    return mini\n",
    "\n",
    "#길이에 맞게 잘라냄\n",
    "def set_length(data, d_mini):\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-2.5602067e-05,  5.1135221e-06, -2.7813609e-05, ...,\n",
       "              -3.8511094e-05, -4.4227359e-05,  0.0000000e+00], dtype=float32),\n",
       "       array([-5.5731027e-05, -1.6563521e-04, -1.9174733e-04, ...,\n",
       "               6.7143403e-05,  8.0324862e-06,  0.0000000e+00], dtype=float32),\n",
       "       array([-9.3971772e-05, -1.4913721e-04, -1.8088850e-04, ...,\n",
       "              -2.7155949e-04, -3.1073933e-04,  0.0000000e+00], dtype=float32),\n",
       "       ...,\n",
       "       array([-3.1695387e-04, -4.7771470e-04, -4.5766350e-04, ...,\n",
       "              -1.0805244e-04, -6.4930202e-05,  0.0000000e+00], dtype=float32),\n",
       "       array([4.9645707e-05, 9.6644086e-05, 1.1572056e-04, ..., 2.0901030e-05,\n",
       "              6.0682945e-05, 1.8038925e-05], dtype=float32)                   ,\n",
       "       array([ 0.00016609,  0.0003012 ,  0.00024623, ..., -0.00029546,\n",
       "              -0.00035234,  0.        ], dtype=float32)               ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, ..., 6, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 작은 길이: 4691\n"
     ]
    }
   ],
   "source": [
    "train_mini = get_mini(train_X)\n",
    "test_mini = get_mini(test_X)\n",
    "\n",
    "mini = np.min([train_mini, test_mini])\n",
    "print('가장 작은 길이:',mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 전처리 결과: (22500, 4691)\n",
      "test 전처리 결과: (7500, 4691)\n"
     ]
    }
   ],
   "source": [
    "#전처리 완료\n",
    "train_X = set_length(train_X, mini)\n",
    "test_X = set_length(test_X, mini)\n",
    "\n",
    "print('train 전처리 결과:',train_X.shape)\n",
    "print('test 전처리 결과:',test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#음성 데이터를 load 했으면 이 음성 데이터의 특징을 추출해야 함.\n",
    "#음성 raw data를 그대로 사용하면 파라미터가 너무 많아지기도 하고 데이터 용량이 너무 커짐.\n",
    "\n",
    "#퓨리에 변환 -> \n",
    "#\"안녕하세요\"라는 말에서, 어떤 사람은 1초, 어떤 사람은 3초가 걸릴 수도 있음\n",
    "# 따라서 이 천차만별인 길이에 대하여 같은 \"안녕하세요\"라는 음성이라고 학습시키기는 어려울 것.\n",
    "# MFCC (Mel-frequency cepstral coefficients) 알고리즘을 이용\n",
    "#   음성데이터를 모두 20~40ms 단위로 쪼개고, 쪼갠 단위에 대해서 Mel값을 뽑아서 Feature로 사용.\n",
    "# Mel-scale : Mel은 사람의 달팽이관을 모티브로 따온 값.\n",
    "#   주파수 대역중에서 감지가 용이한 주파수를 filer, scaling해줄 수 있음-> 이 기준을 Mel-scale 이라 함.\n",
    "\n",
    "#예시로, train_X에서 첫번째 음성의 MFCC 특징을 추출\n",
    "extracted_features = librosa.feature.mfcc(y=train_X[0], sr=16000, n_mfcc=40)\n",
    "extracted_features.shape\n",
    "#출력값: (n_mfcc, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[36m██████████\u001b[0m| 22500/22500 [03:27<00:00, 108.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[36m██████████\u001b[0m| 7500/7500 [01:11<00:00, 104.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataset(data):\n",
    "    mfccs = []\n",
    "    for i in tqdm(data, colour='CYAN'):\n",
    "        extracted_features = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=40)\n",
    "        extracted_features = np.mean(extracted_features.T, axis=0)\n",
    "        mfccs.append(extracted_features)\n",
    "    return mfccs\n",
    "\n",
    "train_X = preprocess_dataset(train_X)\n",
    "train_X = np.array(train_X)\n",
    "print(train_X.shape)\n",
    "\n",
    "test_X = preprocess_dataset(test_X)\n",
    "test_X = np.array(test_X)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.2604041e+02,  1.1418032e+02,  1.3868665e+01, ...,\n",
       "         2.5491018e+00, -3.6942570e+00,  4.7405356e-01],\n",
       "       [-6.2980090e+02,  8.3690216e+01,  2.8933178e+01, ...,\n",
       "         8.6487379e+00, -3.5109191e+00, -5.7271767e-01],\n",
       "       [-6.3775867e+02,  1.3396536e+02,  1.4822125e+01, ...,\n",
       "         2.9129839e+00, -3.6431846e-01,  4.8412247e+00],\n",
       "       ...,\n",
       "       [-5.3629083e+02,  2.4669645e+00,  3.6916222e+01, ...,\n",
       "         1.1425340e+01,  2.4241509e+00,  2.9575248e+00],\n",
       "       [-6.3439972e+02,  8.6175827e+01,  2.5325974e+01, ...,\n",
       "        -1.2430583e+00, -5.4197960e+00,  1.0434834e+00],\n",
       "       [-6.4664111e+02,  1.2939424e+02,  1.3351482e+01, ...,\n",
       "        -4.0698695e+00, -2.2186859e+00,  5.1485538e+00]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, ..., 6, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForestClassifier 모델\n",
    "# 예측해야할 0~9 라벨이 분류 변수\n",
    "# 의사 결정 트리는 feature 별 가지치기를 통해 데이터를 학습하는 알고리즘\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#모델 선언\n",
    "model = RandomForestClassifier()\n",
    "#모델 학습\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#점수를 메기는 방법인 평가 지표(Metric)를 정의\n",
    "def ACCURACY(true, pred):\n",
    "    score = np.mean(true == pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 정확도는 96.83% 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델의 예측과 실제 정답값을 비교.\n",
    "prediction = model.predict(test_X)\n",
    "score = ACCURACY(test_y, prediction)\n",
    "print(f'모델의 정확도는 {score*100:.2f}% 입니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
